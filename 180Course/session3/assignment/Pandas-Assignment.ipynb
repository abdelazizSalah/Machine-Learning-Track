{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 : import the CSV file data/brasil-real-estate-1.csv into dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv \n",
    "# importing csv file \n",
    "brazilDF = pd.read_csv('data.csv')\n",
    "# brazilDF = pd.read_csv('brasil-real-estate-1.csv', encoding='latin')\n",
    "# brazilDF = pd.read_csv('winemag-data-130k-v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2 :Drop all rows with NAN values from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>property_type</th>\n",
       "      <th>place_with_parent_names</th>\n",
       "      <th>region</th>\n",
       "      <th>lat-lon</th>\n",
       "      <th>area_m2</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>apartment</td>\n",
       "      <td>|Brasil|Alagoas|Macei�|</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-9.6443051,-35.7088142</td>\n",
       "      <td>110</td>\n",
       "      <td>$187,230.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 property_type  place_with_parent_names     region  \\\n",
       "0           1     apartment  |Brasil|Alagoas|Macei�|  Northeast   \n",
       "\n",
       "                  lat-lon  area_m2    price_usd  \n",
       "0  -9.6443051,-35.7088142      110  $187,230.85  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brazilDF.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: use \"lat-lon\" columns to create two seperate columns in df \"lat\", \"lon\". make sure that the datatype will be float"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitter\n",
    "* In order to split the \"lat-lon\" column, we must know what is the separator, which separate the data from each other, and this separator is called delimeter.\n",
    "* so in our case it is the comma ','\n",
    "* after that we iterate over the column of lat-lon and split the data, it will return ana array of number of elements which return\n",
    "* so in our case will be 2.\n",
    "* so we take the first element and create for it a new column called \"lat\" and the second element and create for it a new column called \"lon\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-45.3531193\n"
     ]
    }
   ],
   "source": [
    "brazilDF['lat'] , brazilDF['lon']= [float(firstPart.split(',')[0]) for firstPart in brazilDF['lat-lon']],[float(firstPart.split(',')[1]) for firstPart in brazilDF['lat-lon']]\n",
    "print(brazilDF['lat'][0] + brazilDF['lon'][0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Transform \"price_USD\" so that all values be floating points instead of strigns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the data\n",
    "* To be able to finish this requirement we have to neglect he $ sign and to remove all the commas which separate the thousands from the hundreds from the tens and from the units. \n",
    "* so to do this we just need to remove the $ sign and the commas and then convert the data type to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazilDF['price_usd'] = [float(dollar[1:].replace(',', '')) for dollar in brazilDF['price_usd']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: drop \"lat-lon\" columns\n",
    "* we need to avoid shallow droping \n",
    "  * this can be done by setting inplace parameter to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazilDF.drop(columns=['lat-lon'], inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: import the CSV file data/brasil-real-estate-2.csv into dataframe df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>property_type</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>area_m2</th>\n",
       "      <th>price_brl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.134204</td>\n",
       "      <td>-34.906326</td>\n",
       "      <td>72</td>\n",
       "      <td>414222.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.126664</td>\n",
       "      <td>-34.903924</td>\n",
       "      <td>136</td>\n",
       "      <td>848408.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.125550</td>\n",
       "      <td>-34.907601</td>\n",
       "      <td>75</td>\n",
       "      <td>299438.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.120249</td>\n",
       "      <td>-34.895920</td>\n",
       "      <td>187</td>\n",
       "      <td>848408.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.142666</td>\n",
       "      <td>-34.906906</td>\n",
       "      <td>80</td>\n",
       "      <td>464129.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.137671</td>\n",
       "      <td>-34.913349</td>\n",
       "      <td>94</td>\n",
       "      <td>294447.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.141599</td>\n",
       "      <td>-34.909179</td>\n",
       "      <td>80</td>\n",
       "      <td>314410.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 property_type       state     region       lat        lon  \\\n",
       "0           1     apartment  Pernambuco  Northeast -8.134204 -34.906326   \n",
       "1           2     apartment  Pernambuco  Northeast -8.126664 -34.903924   \n",
       "2           3     apartment  Pernambuco  Northeast -8.125550 -34.907601   \n",
       "3           4     apartment  Pernambuco  Northeast -8.120249 -34.895920   \n",
       "4           5     apartment  Pernambuco  Northeast -8.142666 -34.906906   \n",
       "5           6     apartment  Pernambuco  Northeast -8.137671 -34.913349   \n",
       "6           7     apartment  Pernambuco  Northeast -8.141599 -34.909179   \n",
       "\n",
       "   area_m2  price_brl  \n",
       "0       72  414222.98  \n",
       "1      136  848408.53  \n",
       "2       75  299438.28  \n",
       "3      187  848408.53  \n",
       "4       80  464129.36  \n",
       "5       94  294447.66  \n",
       "6       80  314410.19  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brazilDF2 = pd.read_csv('brazilData2.csv')\n",
    "brazilDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: use \"price_berl\" to create new columns named \"price_usd\" by dividing the value by 3.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    129850.463950\n",
       "1    265958.786834\n",
       "2     93867.799373\n",
       "3    265958.786834\n",
       "4    145495.097179\n",
       "5     92303.341693\n",
       "6     98561.188088\n",
       "Name: price_usd, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brazilDF2['price_usd'] = brazilDF2['price_brl'] / 3.19\n",
    "brazilDF2['price_usd']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: drop \"price_brl\" from columns, as well as any rows that have Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>property_type</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>area_m2</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.134204</td>\n",
       "      <td>-34.906326</td>\n",
       "      <td>72</td>\n",
       "      <td>129850.463950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.126664</td>\n",
       "      <td>-34.903924</td>\n",
       "      <td>136</td>\n",
       "      <td>265958.786834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.125550</td>\n",
       "      <td>-34.907601</td>\n",
       "      <td>75</td>\n",
       "      <td>93867.799373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.120249</td>\n",
       "      <td>-34.895920</td>\n",
       "      <td>187</td>\n",
       "      <td>265958.786834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.142666</td>\n",
       "      <td>-34.906906</td>\n",
       "      <td>80</td>\n",
       "      <td>145495.097179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.137671</td>\n",
       "      <td>-34.913349</td>\n",
       "      <td>94</td>\n",
       "      <td>92303.341693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.141599</td>\n",
       "      <td>-34.909179</td>\n",
       "      <td>80</td>\n",
       "      <td>98561.188088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 property_type       state     region       lat        lon  \\\n",
       "0           1     apartment  Pernambuco  Northeast -8.134204 -34.906326   \n",
       "1           2     apartment  Pernambuco  Northeast -8.126664 -34.903924   \n",
       "2           3     apartment  Pernambuco  Northeast -8.125550 -34.907601   \n",
       "3           4     apartment  Pernambuco  Northeast -8.120249 -34.895920   \n",
       "4           5     apartment  Pernambuco  Northeast -8.142666 -34.906906   \n",
       "5           6     apartment  Pernambuco  Northeast -8.137671 -34.913349   \n",
       "6           7     apartment  Pernambuco  Northeast -8.141599 -34.909179   \n",
       "\n",
       "   area_m2      price_usd  \n",
       "0       72  129850.463950  \n",
       "1      136  265958.786834  \n",
       "2       75   93867.799373  \n",
       "3      187  265958.786834  \n",
       "4       80  145495.097179  \n",
       "5       94   92303.341693  \n",
       "6       80   98561.188088  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brazilDF2.drop(columns=['price_brl'], inplace=True)\n",
    "brazilDF2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9: concatenate df and df2 into new dataframe named df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>property_type</th>\n",
       "      <th>place_with_parent_names</th>\n",
       "      <th>region</th>\n",
       "      <th>area_m2</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>property_type</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>area_m2</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>apartment</td>\n",
       "      <td>|Brasil|Alagoas|Macei�|</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>110.0</td>\n",
       "      <td>187230.85</td>\n",
       "      <td>-9.644305</td>\n",
       "      <td>-35.708814</td>\n",
       "      <td>1</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.134204</td>\n",
       "      <td>-34.906326</td>\n",
       "      <td>72</td>\n",
       "      <td>129850.463950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.126664</td>\n",
       "      <td>-34.903924</td>\n",
       "      <td>136</td>\n",
       "      <td>265958.786834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.125550</td>\n",
       "      <td>-34.907601</td>\n",
       "      <td>75</td>\n",
       "      <td>93867.799373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.120249</td>\n",
       "      <td>-34.895920</td>\n",
       "      <td>187</td>\n",
       "      <td>265958.786834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.142666</td>\n",
       "      <td>-34.906906</td>\n",
       "      <td>80</td>\n",
       "      <td>145495.097179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.137671</td>\n",
       "      <td>-34.913349</td>\n",
       "      <td>94</td>\n",
       "      <td>92303.341693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>-8.141599</td>\n",
       "      <td>-34.909179</td>\n",
       "      <td>80</td>\n",
       "      <td>98561.188088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 property_type  place_with_parent_names     region  area_m2  \\\n",
       "0         1.0     apartment  |Brasil|Alagoas|Macei�|  Northeast    110.0   \n",
       "1         NaN           NaN                      NaN        NaN      NaN   \n",
       "2         NaN           NaN                      NaN        NaN      NaN   \n",
       "3         NaN           NaN                      NaN        NaN      NaN   \n",
       "4         NaN           NaN                      NaN        NaN      NaN   \n",
       "5         NaN           NaN                      NaN        NaN      NaN   \n",
       "6         NaN           NaN                      NaN        NaN      NaN   \n",
       "\n",
       "   price_usd       lat        lon  Unnamed: 0 property_type       state  \\\n",
       "0  187230.85 -9.644305 -35.708814           1     apartment  Pernambuco   \n",
       "1        NaN       NaN        NaN           2     apartment  Pernambuco   \n",
       "2        NaN       NaN        NaN           3     apartment  Pernambuco   \n",
       "3        NaN       NaN        NaN           4     apartment  Pernambuco   \n",
       "4        NaN       NaN        NaN           5     apartment  Pernambuco   \n",
       "5        NaN       NaN        NaN           6     apartment  Pernambuco   \n",
       "6        NaN       NaN        NaN           7     apartment  Pernambuco   \n",
       "\n",
       "      region       lat        lon  area_m2      price_usd  \n",
       "0  Northeast -8.134204 -34.906326       72  129850.463950  \n",
       "1  Northeast -8.126664 -34.903924      136  265958.786834  \n",
       "2  Northeast -8.125550 -34.907601       75   93867.799373  \n",
       "3  Northeast -8.120249 -34.895920      187  265958.786834  \n",
       "4  Northeast -8.142666 -34.906906       80  145495.097179  \n",
       "5  Northeast -8.137671 -34.913349       94   92303.341693  \n",
       "6  Northeast -8.141599 -34.909179       80   98561.188088  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.concat([brazilDF, brazilDF2], axis=1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10: use describe method to create dataframe summary_stats for \"area_m2\" and \"price_usd\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       area_m2     area_m2\n",
       " count      1.0    7.000000\n",
       " mean     110.0  103.428571\n",
       " std        NaN   42.871347\n",
       " min      110.0   72.000000\n",
       " 25%      110.0   77.500000\n",
       " 50%      110.0   80.000000\n",
       " 75%      110.0  115.000000\n",
       " max      110.0  187.000000,\n",
       "        price_usd      price_usd\n",
       " count       1.00       7.000000\n",
       " mean   187230.85  155999.351993\n",
       " std          NaN   77666.930509\n",
       " min    187230.85   92303.341693\n",
       " 25%    187230.85   96214.493730\n",
       " 50%    187230.85  129850.463950\n",
       " 75%    187230.85  205726.942006\n",
       " max    187230.85  265958.786834]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this if we want each alone\n",
    "df_new['area_m2'].describe()\n",
    "df_new['price_usd'].describe()\n",
    "\n",
    "## this if we want both of them together\n",
    "description = [df_new['area_m2'].describe(), df_new['price_usd'].describe()]\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 11: use groupby method to create a series named mean_price_by_region that shows the mean home price in brazil, sorted from smallest to highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grouper for 'region' not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\GitHub\\Machine-Learning-Track\\180Course\\session3\\assignment\\Pandas-Assignment.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Machine-Learning-Track/180Course/session3/assignment/Pandas-Assignment.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# mean_price_by_region = df_new.groupby('price_usd')\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/GitHub/Machine-Learning-Track/180Course/session3/assignment/Pandas-Assignment.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mean_price_by_region \u001b[39m=\u001b[39m df_new\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mregion\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mprice_usd\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39msort_values()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Machine-Learning-Track/180Course/session3/assignment/Pandas-Assignment.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mean_price_by_region\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7707\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7709\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7710\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7711\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7712\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   7713\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   7714\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   7715\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   7716\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   7717\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   7718\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   7719\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   7720\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7721\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   7722\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   7723\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    883\u001b[0m         obj,\n\u001b[0;32m    884\u001b[0m         keys,\n\u001b[0;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\groupby\\grouper.py:877\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    873\u001b[0m     in_axis, name, gpr \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, gpr, obj[gpr]\n\u001b[0;32m    874\u001b[0m     \u001b[39mif\u001b[39;00m gpr\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    875\u001b[0m         \u001b[39m# non-unique columns; raise here to get the name in the\u001b[39;00m\n\u001b[0;32m    876\u001b[0m         \u001b[39m# exception message\u001b[39;00m\n\u001b[1;32m--> 877\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGrouper for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    878\u001b[0m     exclusions\u001b[39m.\u001b[39madd(name)\n\u001b[0;32m    879\u001b[0m \u001b[39melif\u001b[39;00m obj\u001b[39m.\u001b[39m_is_level_reference(gpr, axis\u001b[39m=\u001b[39maxis):\n",
      "\u001b[1;31mValueError\u001b[0m: Grouper for 'region' not 1-dimensional"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# mean_price_by_region = df_new.groupby('price_usd')\n",
    "mean_price_by_region = df_new.groupby('region')['price_usd'].mean().sort_values()\n",
    "mean_price_by_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 12: create new dataframe named df_south that contains all homes from df in South region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: region, dtype: object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_south = brazilDF.loc[brazilDF['region'] == 'South' , 'region']\n",
    "df_south"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 13: use value_counts method to ctreate a series home_by_state that contains the number of properties in df_south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: region, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_by_state = df_south.value_counts()\n",
    "home_by_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 14: Write a wrangle function that takes the name of csv as argument and perform the following : \n",
    "\n",
    "1- read mexico-real-estate-1.csv into df \n",
    "\n",
    "2- get only the apartment that locates in mexico city \"Distrito Federal\" that costs less than 100,000\n",
    "\n",
    "3- create seperate \"lat\" and \"lon\" columns as done before\n",
    "\n",
    "4- drop columns that are more than 50 % Nan values\n",
    "\n",
    "5- drop all columns with categorical values\n",
    "\n",
    "6- return df at last "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle (csvPath): # assume they provide the full path with .csv extension\n",
    "    # reading the csv file\n",
    "    df = pd.read_csv(csvPath, encoding='latin')\n",
    "    # coverting price into float \n",
    "    df['price_usd'] = [float(dollar[1:].replace(',', '')) for dollar in brazilDF['price_usd']]\n",
    "    # getting only the appartment that locates in mexico city and costs less\n",
    "    appartments = df.loc(df['state'] == 'Distrito Federal' and df['price_usd'] < 100000.0)\n",
    "    # create a seperate lat and lon\n",
    "    # df['lat'], df['lon'] = [first.split(',')[0] for first in df['lat-lon']], [first.split(',')[1] for first in df['lat-lon']]\n",
    "    ## THIS IS ANOTHER WAY FOR SOLUTION USING MAP.\n",
    "    df['lat'] = df['lat-lon'].map(lambda x: float(x.split(',')[0]))\n",
    "    df['lon'] = df['lat-lon'].map(lambda x: float(x.split(',')[1]))\n",
    "    df.head()\n",
    "    # droping columns with more than 50% nan\n",
    "    df.drop(columns=[(df.isnull().mean() * 100) > 50], inplace= True)\n",
    "    # droping all columns with categorical values\n",
    "    df = df.select_dtypes(exclude='category')\n",
    "    #returning df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use glob method to create list of files. it should contains the filename of all mexico real state. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glob library \n",
    "\n",
    "```python \n",
    "import glob as gp\n",
    "\n",
    "mydir = \"{Path}\"\n",
    "\n",
    "file_list = gp.glob(mydir + \"*.csv\")\n",
    "print('file_list {}'.format(file_list))\n",
    "```\n",
    "this is how we can get a list of all files which ends with csv in a specific directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\mexico-real-estate-1.csv',\n",
       " '.\\\\mexico-real-estate-2.csv',\n",
       " '.\\\\mexico-real-estate-3.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob as gp \n",
    "files = gp.glob('./mexico-real-estate*')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine your wrangle function, a list comprehnsion and pd.concat to create new dataframe df from all files names from previous task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDf = pd.concat([wrangle(df) for df in files], axis= 1 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assingment is done Except \n",
    "1. task 11\n",
    "2. to read the actual file, because it is not in utf-8 but it is in latin, so we have problem with floating point numbers\n",
    "3. so I just read some lines, and applied the correct logic, then I will try to solve it later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Abdelaziz Salah \n",
    "* Date 27/3/2023 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
